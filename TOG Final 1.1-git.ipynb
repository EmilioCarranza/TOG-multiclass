{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18493bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#plots\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "#Data Handling\n",
    "from sklearn.preprocessing import (Normalizer,StandardScaler,MinMaxScaler)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Genetic Modules\n",
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import rcParams\n",
    "from cycler import cycler\n",
    "#Log Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, recall_score, precision_score,\n",
    "                             f1_score,balanced_accuracy_score)\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "# metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,r2_score\n",
    "# Neural Network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import seaborn as sb\n",
    "import graphviz\n",
    "import pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from  sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "route = 'C:/Users/Emilio/Desktop/TOG Exp/Datasets/'\n",
    "# data = pd.read_parquet(route+'ohlcV.parquet')\n",
    "# data = pd.read_parquet(route+'ohlc-2017.parquet')\n",
    "data = pd.read_parquet(route + 'ohlc-2021.parquet')\n",
    "#data = pd.read_parquet(route + 'ohlc1.parquet')\n",
    "data = data.drop(['drop', 'close_time'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80130eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Quick description of the data\n",
    "desc = data.describe()\n",
    "info = data.info()\n",
    "print(desc, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "data.iloc[:,:-5].hist(bins=50, figsize=(20, 15))\n",
    "plt.show()\n",
    "\n",
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,+4:].hist(bins=50, figsize=(20, 15))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Resampling\n",
    "rs = '5min'\n",
    "data1 = data.copy()\n",
    "data1['open'] = data1['open'].resample(rs).first()\n",
    "data1['high'] = data1['high'].resample(rs).max()\n",
    "data1['low'] = data1['low'].resample(rs).min()\n",
    "data1['close'] = data1['close'].resample(rs).last()\n",
    "data1['volume'] = data1['volume'].resample(rs).sum()\n",
    "data1['quote_asset_volume'] = data1['quote_asset_volume'].resample(rs).sum()\n",
    "data1['trades'] = data1['trades'].resample(rs).sum()\n",
    "data1['buy_asset_volume'] = data1['buy_asset_volume'].resample(rs).sum()\n",
    "data1['taker_buy_asset_volume'] = data1['taker_buy_asset_volume'].resample(rs).sum()\n",
    "data1 = data1.resample(rs).sum()\n",
    "print(data1.shape)\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Feature Engineering\n",
    "\n",
    "ohlcv = data1.copy()\n",
    "# OHLC Chart\n",
    "fig = go.Figure(data=go.Ohlc(x=ohlcv.index,\n",
    "                             open=ohlcv['open'],\n",
    "                             high=ohlcv['high'],\n",
    "                             low=ohlcv['low'],\n",
    "                             close=ohlcv['close']))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "volatility = []\n",
    "for i in range(len(ohlcv)):\n",
    "    vol = ohlcv['high'][i] - ohlcv['low'][i]\n",
    "    volatility.append(vol)\n",
    "ohlcv['volatility'] = volatility\n",
    "\n",
    "# micro trends\n",
    "high_open = []\n",
    "for i in range(len(ohlcv)):\n",
    "    ho = ohlcv['high'][i] - ohlcv['open'][i]\n",
    "    high_open.append(ho)\n",
    "ohlcv['high_open'] = high_open\n",
    "\n",
    "open_low = []\n",
    "for i in range(len(ohlcv)):\n",
    "    ol = ohlcv['open'][i] - ohlcv['low'][i]\n",
    "    open_low.append(ol)\n",
    "ohlcv['open_low'] = open_low\n",
    "\n",
    "close_open = []\n",
    "for i in range(len(ohlcv)):\n",
    "    co = ohlcv['close'][i] - ohlcv['open'][i]\n",
    "    close_open.append(co)\n",
    "ohlcv['close_open'] = close_open\n",
    "ohlcv.head()\n",
    "\n",
    "ohlcv2 = ohlcv.copy()\n",
    "ohlcv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c62a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Rolling stats\n",
    "ohlcv2 = ohlcv2.drop(['quote_asset_volume', 'buy_asset_volume', 'taker_buy_asset_volume', 'trades'], axis=1)\n",
    "\n",
    "def autoregressive_features(p_data, p_memory):\n",
    "    \"\"\"\n",
    "    Creacion de variables de naturaleza autoregresiva (resagos, promedios, diferencias)\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_data: pd.DataFrame\n",
    "        with OHLCV columns: Open, High, Low, Close, Volume\n",
    "    p_memory: int\n",
    "        A value that represents the implicit assumption of a \"memory\" effect in the prices\n",
    "    Returns\n",
    "    -------\n",
    "    r_features: pd.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # work with a separate copy of original data\n",
    "    data = ohlcv2.copy()\n",
    "\n",
    "    # nth-period final price \"movement\"\n",
    "    data['co'] = (data['close'] - data['open'])\n",
    "    # nth-period uptrend movement\n",
    "    data['ho'] = (data['high'] - data['open'])\n",
    "    # nth-period downtrend movement\n",
    "    data['ol'] = (data['open'] - data['low'])\n",
    "    # nth-period volatility measure\n",
    "    data['hl'] = (data['high'] - data['low'])\n",
    "\n",
    "    # N features with window-based calculations\n",
    "    for n in range(0, p_memory):\n",
    "        data['ma_ol'] = data['ol'].rolling(n + 2).mean()\n",
    "        data['ma_ho'] = data['ho'].rolling(n + 2).mean()\n",
    "        data['ma_hl'] = data['hl'].rolling(n + 2).mean()\n",
    "\n",
    "        data['lag_ol_' + str(n + 1)] = data['ol'].shift(n + 1)\n",
    "        data['lag_ho_' + str(n + 1)] = data['ho'].shift(n + 1)\n",
    "        data['lag_hl_' + str(n + 1)] = data['hl'].shift(n + 1)\n",
    "\n",
    "        data['sd_ol_' + str(n + 1)] = data['ol'].rolling(n + 1).std()\n",
    "        data['sd_ho_' + str(n + 1)] = data['ho'].rolling(n + 1).std()\n",
    "        data['sd_hl_' + str(n + 1)] = data['hl'].rolling(n + 1).std()\n",
    "\n",
    "        data['lag_vol_' + str(n + 1)] = data['volume'].shift(n + 1)\n",
    "        data['sum_vol_' + str(n + 1)] = data['volume'].rolling(n + 1).sum()\n",
    "        data['mean_vol_' + str(n + 1)] = data['volume'].rolling(n + 1).mean()\n",
    "\n",
    "    # timestamp as index\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    # select columns, drop for NAs, change column types, reset index\n",
    "    r_features = data.drop(['open', 'high', 'low', 'close', 'hl', 'ol', 'ho', 'volume'], axis=1)\n",
    "    r_features = r_features.dropna(axis='columns', how='all')\n",
    "    # r_features = r_features.dropna(axis='rows')\n",
    "    r_features.iloc[:, 1:] = r_features.iloc[:, 1:].astype(float)\n",
    "    r_features.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return r_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_memory = 24\n",
    "data_ar = autoregressive_features(p_data=ohlcv2, p_memory=p_memory)\n",
    "data_ar.index = ohlcv2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv = pd.merge(ohlcv, data_ar, on='timestamp')\n",
    "ohlcv = ohlcv.dropna(axis='rows')\n",
    "ohlcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv['co'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61da3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile= abs(ohlcv['co'].quantile(.25)) + abs(ohlcv['co'].quantile(.75))\n",
    "treshold1 =ohlcv['co'].quantile(.25)\n",
    "treshold2 =ohlcv['co'].quantile(.50)\n",
    "treshold3 = ohlcv['co'].quantile(.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cd995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target \n",
    "# %% Target Engineering y_hat:CO_{t}\n",
    "\n",
    "\n",
    "ohlc = pd.DataFrame(ohlcv)\n",
    "\n",
    "y_hat = []\n",
    "\n",
    "for i in range(len(ohlc)):\n",
    "    y_hat1 = ohlc[\"close\"][i] - ohlc[\"open\"][i]\n",
    "    y_hat.append(y_hat1)\n",
    "for i in range(len(ohlc)):\n",
    "    if y_hat[i] < treshold1:\n",
    "        y_hat[i] = -2\n",
    "    elif treshold1 <= y_hat[i] < 0:\n",
    "        y_hat[i] = -1\n",
    "    elif y_hat[i] == 0:\n",
    "        y_hat[i] = -1\n",
    "    elif 0 < y_hat[i] <= treshold3:\n",
    "        y_hat[i] = 1\n",
    "    else:\n",
    "        y_hat[i] = 2\n",
    "# cambiar y_hat por y_hat\n",
    "ohlc['y_hat'] = y_hat\n",
    "y_hat_test = y_hat\n",
    "ohlc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc['y_hat'] = y_hat\n",
    "ohlc['y_hat'] = ohlc['y_hat'].shift(-1)\n",
    "# ohlc.dropna(inplace = True, axis=0)\n",
    "ohlc.head()\n",
    "ohlc['y_hat'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "mart = []\n",
    "# cambiar threshold a variables, en vez de hardcode que defina las clases y puede ser asimetrica.\n",
    "for i in range(len(ohlc)):\n",
    "    y_hat1 = ohlc[\"close\"][i] - ohlc[\"open\"][i]\n",
    "    mart.append(y_hat1)\n",
    "for i in range(len(ohlc)):\n",
    "    if mart[i] < treshold1:\n",
    "        mart[i] = -2\n",
    "    elif treshold1 <= mart[i] < 0:\n",
    "        mart[i] = -1\n",
    "    elif mart[i] == 0:\n",
    "        mart[i] = -1\n",
    "    elif 0 < mart[i] <= treshold3:\n",
    "        mart[i] = 1\n",
    "    else:\n",
    "        mart[i] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Martingale\n",
    "\n",
    "ohlc['martingale'] = mart\n",
    "ohlc['martingale'] = ohlc['martingale'].shift(+1)\n",
    "ohlc = ohlc.fillna(-1)\n",
    "ohlc2 = pd.DataFrame(ohlc)\n",
    "ohlc2.to_csv('C:/Users/Emilio/Desktop/Thesis/ohlc2.csv')\n",
    "ohlc2['martingale'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c505193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ohlc['y_hat'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_martingala = accuracy_score(y_hat_test, ohlc2['martingale']) * 100\n",
    "recall_martingala = recall_score(y_hat_test, ohlc2['martingale'], average='weighted') * 100\n",
    "precision_martingala = precision_score(y_hat_test, ohlc2['martingale'], average='weighted') * 100\n",
    "f1_martingala = f1_score(y_hat_test, ohlc2['martingale'], average='weighted') * 100\n",
    "balanced_martingala = balanced_accuracy_score(y_hat_test, ohlc2['martingale']) * 100\n",
    "\n",
    "print('Accuracy:', accuracy_martingala, '%')\n",
    "print('Recall:', recall_martingala, '%')\n",
    "print('Precision:', precision_martingala, '%')\n",
    "print('F1:', f1_martingala, '%')\n",
    "print('Balanced Accuracy:', balanced_martingala, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mart = confusion_matrix(ohlc2['y_hat'], ohlc2['martingale'])\n",
    "print(confusion_mart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0aa32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, px = plt.subplots(figsize=(4, 4))\n",
    "px.matshow(confusion_mart, cmap=plt.cm.YlOrRd, alpha=0.5)\n",
    "for m in range(confusion_mart.shape[0]):\n",
    "    for n in range(confusion_mart.shape[1]):\n",
    "        px.text(x=m, y=n, s=confusion_mart[m, n], va='center', ha='center', size='large')\n",
    "\n",
    "# Sets the labels\n",
    "plt.xlabel('Predictions', fontsize=16)\n",
    "plt.ylabel('Actual', fontsize=16)\n",
    "plt.title('Confusion Matrix Martingale', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd01a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc2['y_hat'].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ohlc2['y_hat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd92f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(ohlc2['y_hat'], notch=None, vert=None, patch_artist=None, widths=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_y = ohlc2.corrwith(ohlc2['y_hat']).abs()\n",
    "corr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d643b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ohlc2.iloc[:, :-2]\n",
    "X.head()\n",
    "y = ohlc2['y_hat'].copy()\n",
    "y_true = y.copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64aa98",
   "metadata": {},
   "source": [
    "# %% Heatmaps\n",
    "# Heat map\n",
    "correlation = X.corr()\n",
    "print(correlation)\n",
    "\n",
    "heat = sns.heatmap(\n",
    "    correlation,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "heat.set_xticklabels(\n",
    "    heat.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a864810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = X.corr() \n",
    "print(correlation)\n",
    "\n",
    "heat = sns.heatmap( correlation, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=False ) \n",
    "heat.set_xticklabels( heat.get_xticklabels(), rotation=90, horizontalalignment='right' ) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = correlation[correlation >= .80]\n",
    "corr2 = corr.corr(method='spearman')\n",
    "print(corr2)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = correlation[correlation >= .80]\n",
    "corr2 = corr.corr(method='pearson')\n",
    "print(corr2)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, cmap=\"Reds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_matrix = X.corr().abs()\n",
    "print(cor_matrix)\n",
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))\n",
    "print(upper_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11749fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .5 according to JF, but not many features after that.\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] >= .80)]\n",
    "print();\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a90e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.drop(X[to_drop], axis=1)\n",
    "print();\n",
    "print(x.head())\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best = SelectKBest(k=50)\n",
    "x_new= best.fit_transform(x,y)\n",
    "x_new.shape\n",
    "selected = best.get_support(indices=True)\n",
    "print(x.columns[selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34206c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_features = x.columns[selected]\n",
    "plt.title('Correlación de Características Seleccionadas');\n",
    "sb.heatmap(x[used_features].astype(float).corr(),\n",
    "           linewidths=0.1,\n",
    "           vmax=1.0, \n",
    "           square=False, \n",
    "           cmap='viridis', \n",
    "           linecolor='white', \n",
    "           annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb96734",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_neo = x[used_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Min Max Scaler\n",
    "scale = MinMaxScaler().fit(x_neo)\n",
    "X_scale = scale.transform(x_neo)\n",
    "X_scale = pd.DataFrame(X_scale, index=x_neo.index, columns=x_neo.columns)\n",
    "X_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375db219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer\n",
    "transformer = Normalizer(norm='max').fit(X_scale)\n",
    "transformed = transformer.transform(X_scale)\n",
    "X_normalized = pd.DataFrame(transformed, index=x_neo.index, columns=x_neo.columns)\n",
    "X_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_normalized.copy()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33897f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 5\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.prop_cycle'] = cycler(color=['#365977'])\n",
    "rcParams['lines.linewidth'] = 2.5\n",
    "plt.title('x', size=20)\n",
    "plt.plot(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffdc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 5\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.prop_cycle'] = cycler(color=['#365977'])\n",
    "rcParams['lines.linewidth'] = .5\n",
    "plt.title('Y', size=20)\n",
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(len(x) * .30)\n",
    "trial_size = int(len(x) * .10)\n",
    "X_train = x[:-test_size].copy()\n",
    "X_test = x[-test_size:].copy()\n",
    "X_test = X_test[:-trial_size].copy()\n",
    "X_trial = X_test[-trial_size:].copy()\n",
    "\n",
    "X_train2 = X_train.copy()\n",
    "X_test2 = X_test.copy()\n",
    "X_trial2 = X_trial.copy()\n",
    "\n",
    "X_train3 = X_train.copy()\n",
    "X_test3 = X_test.copy()\n",
    "X_trial3 = X_trial.copy()\n",
    "\n",
    "X_train4 = X_train.copy()\n",
    "X_test4 = X_test.copy()\n",
    "X_trial4 = X_trial.copy()\n",
    "\n",
    "X_train5 = X_train.copy()\n",
    "X_test5 = X_test.copy()\n",
    "X_trial5 = X_trial.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('X', size=20)\n",
    "plt.plot(X_train)  # ,label='Training set')\n",
    "plt.plot(X_test, label='Test set', color='orange')\n",
    "plt.plot(X_trial,label= 'Trial set',color='green')\n",
    "plt.legend;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b88356",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[:-test_size].copy()\n",
    "y_test = y[-test_size:].copy()\n",
    "y_test = y_test[:-trial_size].copy()\n",
    "y_trial = y_test[-trial_size:].copy()\n",
    "\n",
    "y_train2 = y_train.copy()\n",
    "y_test2 = y_test.copy()\n",
    "y_trial2 = y_trial.copy()\n",
    "\n",
    "y_train3 = y_train.copy()\n",
    "y_test3 = y_test.copy()\n",
    "y_trial3 = y_trial.copy()\n",
    "\n",
    "y_train4 = y_train.copy()\n",
    "y_test4 = y_test.copy()\n",
    "y_trial4 = y_trial.copy()\n",
    "\n",
    "y_train5 = y_train.copy()\n",
    "y_test5 = y_test.copy()\n",
    "y_trial5 = y_trial.copy()\n",
    "\n",
    "Y_train_dum = pd.get_dummies(y_train5, prefix='y')\n",
    "Y_test_dum = pd.get_dummies(y_test5, prefix='y')\n",
    "Y_trial_dum = pd.get_dummies(y_trial5,prefix='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9e0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('y', size=20)\n",
    "plt.plot(y_train, label='Training set')\n",
    "plt.plot(y_test, label='Test set', color='orange')\n",
    "plt.plot(y_trial,label='Trial set',color='green')\n",
    "plt.legend;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8121596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes\n",
    "# %% Naive Bayes\n",
    "print(X_train.shape, X_test.shape)\n",
    "# instantiate the model\n",
    "gnb = GaussianNB()\n",
    "# gnb = CategoricalNB()\n",
    "# pgmpy()\n",
    "\n",
    "# fit the model\n",
    "gnb.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176aab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = gnb.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_naive = (accuracy_score(y_test2, y_pred2)) * 100\n",
    "recall_naive = recall_score(y_test2, y_pred2, average='weighted') * 100\n",
    "precision_naive = precision_score(y_test2, y_pred2, average='weighted', zero_division=0) * 100\n",
    "f1_naive = f1_score(y_test2, y_pred2, average='weighted') * 100\n",
    "balanced_naive = balanced_accuracy_score(y_test2, y_pred2) * 100\n",
    "print('Accuracy:', accuracy_naive, '%')\n",
    "print('Recall:', recall_naive, '%')\n",
    "print('Precision:', precision_naive, '%')\n",
    "print('F1:', f1_naive, '%')\n",
    "print('Balanced Accuracy:', balanced_naive, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edd979",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = gnb.predict(X_train2)\n",
    "conf_mat = confusion_matrix(y_test2, y_pred2)\n",
    "fig, px = plt.subplots(figsize=(3.5, 3.5))\n",
    "px.matshow(conf_mat, cmap=plt.cm.YlOrRd, alpha=0.5)\n",
    "for m in range(conf_mat.shape[0]):\n",
    "    for n in range(conf_mat.shape[1]):\n",
    "        px.text(x=m, y=n, s=conf_mat[m, n], va='center', ha='center', size='large')\n",
    "# Sets the labels\n",
    "plt.xlabel('Predictions', fontsize=16)\n",
    "plt.ylabel('Actual', fontsize=16)\n",
    "plt.title('Confusion Matrix Naive Bayes', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911092da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2_trial = gnb.predict(X_trial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_naive2 = (accuracy_score(y_trial2, y_pred2_trial)) * 100\n",
    "recall_naive2 = recall_score(y_trial2, y_pred2_trial, average='weighted') * 100\n",
    "precision_naive2 = precision_score(y_trial2, y_pred2_trial, average='weighted', zero_division=0) * 100\n",
    "f1_naive2 = f1_score(y_trial2, y_pred2_trial, average='weighted') * 100\n",
    "balanced_naive2 = balanced_accuracy_score(y_trial2, y_pred2_trial) * 100\n",
    "print('Accuracy:', accuracy_naive2, '%')\n",
    "print('Recall:', recall_naive2, '%')\n",
    "print('Precision:', precision_naive2, '%')\n",
    "print('F1:', f1_naive2, '%')\n",
    "print('Balanced Accuracy:', balanced_naive2, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression simple\n",
    "logistic_model_simple = LogisticRegression(max_iter=1000000)\n",
    "logistic_model_simple.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff374de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_model.predict_proba((X[:2, :])\n",
    "y_pred = logistic_model_simple.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "logistic_model_simple.score(x, y)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_simple.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si fueron 0 se quitaron por efecto de la regularizacion L1 y son:\n",
    "# si\n",
    "coef = logistic_model_simple.coef_\n",
    "print(logistic_model_simple.intercept_)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be61bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ = logistic_model_simple.predict_proba(X_train)\n",
    "print(predict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ac4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test, y_pred, 'r')\n",
    "plt.plot(X, y_true, 'b')\n",
    "plt.axis([1, 30000, -3, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_simple = logistic_model_simple.predict(X_test)\n",
    "accuracy_logistic_simple = accuracy_score(y_test, y_pred) * 100\n",
    "logistic_model_simple.score(x, y)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "recall_logistic_simple = recall_score(y_test, y_pred, average='weighted') * 100\n",
    "precision_logistic_simple = precision_score(y_test, y_pred, average='weighted', zero_division=0) * 100\n",
    "f1_logistic_simple = f1_score(y_test, y_pred, average='weighted') * 100\n",
    "balanced_logistic_simple = balanced_accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "print('Accuracy:', accuracy_logistic_simple, '%')\n",
    "print('Recall:', recall_logistic_simple, '%')\n",
    "print('Precision:', precision_logistic_simple, '%')\n",
    "print('F1:', f1_logistic_simple, '%')\n",
    "print('Balanced Accuracy:', balanced_logistic_simple, '%')\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bfce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_simple2 = logistic_model_simple.predict(X_trial)\n",
    "accuracy = accuracy_score(y_trial, y_pred_simple2) * 100\n",
    "logistic_model_simple.score(x, y)\n",
    "confusion_mat = confusion_matrix(y_trial, y_pred_simple2)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with Elastic Net and hiper parameters optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c7ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineLR = make_pipeline(\n",
    "LogisticRegression(random_state=False, penalty='elasticnet',solver ='saga', max_iter=1000000, C=1\n",
    " ))\n",
    "param_grid_lr = [{\n",
    "    'logisticregression__l1_ratio':[.10,.20,.30,.40,.50,.60,.70,.80,.90],\n",
    "    'logisticregression__class_weight':[None],\n",
    "    'logisticregression__C':[0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 10.0],\n",
    "    'logisticregression__solver':['saga']\n",
    "}]\n",
    "gd_lm = GridSearchCV(estimator=pipelineLR,\n",
    "                     param_grid=param_grid_lr,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10,\n",
    "                     n_jobs=-1)\n",
    "gd_lm.fit(X_train3, y_train3)\n",
    "print(gd_lm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53235326",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_lm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7a269",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfLR = gd_lm.best_estimator_\n",
    "clfLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfLR.score(X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(random_state=False, penalty='elasticnet',\n",
    "                                            solver='saga', l1_ratio=0.4, max_iter=1000000, C=10,\n",
    "                                            class_weight= None, )\n",
    "logistic_model.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = logistic_model.predict(X_test3)\n",
    "accuracy = accuracy_score(y_test3, y_pred3) * 100\n",
    "logistic_model.score(x, y)\n",
    "confusion_mat = confusion_matrix(y_test3, y_pred3)\n",
    "\n",
    "y_pred_trial = logistic_model.predict(X_trial3)\n",
    "accuracy_trial = accuracy_score(y_trial3, y_pred_trial) * 100\n",
    "logistic_model.score(x, y)\n",
    "print(accuracy)\n",
    "print(accuracy_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clfLR, open('logg1.1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01188173",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_logistic= accuracy_score(y_test3, y_pred3) * 100\n",
    "recall_logistic = recall_score(y_test3, y_pred3, average='weighted') * 100\n",
    "precision_logistic = precision_score(y_test3, y_pred3, average='weighted', zero_division=0) * 100\n",
    "f1_logistic = f1_score(y_test3, y_pred3, average='weighted') * 100\n",
    "balanced_logistic = balanced_accuracy_score(y_test3, y_pred3) * 100\n",
    "\n",
    "print('Accuracy:', accuracy_logistic, '%')\n",
    "print('Recall:', recall_logistic, '%')\n",
    "print('Precision:', precision_logistic, '%')\n",
    "print('F1:', f1_logistic, '%')\n",
    "print('Balanced Accuracy:', balanced_logistic, '%')\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325afa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, px = plt.subplots(figsize=(3.5, 3.5))\n",
    "px.matshow(confusion_mat, cmap=plt.cm.YlOrRd, alpha=0.5)\n",
    "for m in range(confusion_mat.shape[0]):\n",
    "    for n in range(confusion_mat.shape[1]):\n",
    "        px.text(x=m, y=n, s=confusion_mat[m, n], va='center', ha='center', size='large')\n",
    "\n",
    "# Sets the labels\n",
    "plt.xlabel('Predictions', fontsize=16)\n",
    "plt.ylabel('Actuals', fontsize=16)\n",
    "plt.title('Confusion Matrix Regresion Log', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f82c4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c662d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineRFC = make_pipeline(\n",
    "RandomForestClassifier(max_depth=None,\n",
    "                       min_samples_split=2,\n",
    "                       max_features='auto',\n",
    "                       n_estimators=1000,\n",
    "                       bootstrap=True,\n",
    "                       oob_score=False,\n",
    "                       verbose=1))\n",
    "\n",
    "param_grid_rfc = [{\n",
    "    'randomforestclassifier__max_features':['sqrt', 'log2', None],\n",
    "    'randomforestclassifier__criterion':['gini','entropy','log_loss'],\n",
    "    #'ranfomforestclassifier__n_estimators':[100, 500,1000]    \n",
    "}]\n",
    "\n",
    "gsrfc =GridSearchCV(estimator= pipelineRFC,\n",
    "                   param_grid=param_grid_rfc,\n",
    "                   scoring='accuracy',\n",
    "                   cv=10,\n",
    "                   n_jobs=1)\n",
    "gs_rfc =gsrfc.fit(X_train4,y_train4)\n",
    "print(gs_rfc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_rfc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afde504",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRFC = gs_rfc.best_estimator_\n",
    "clfRFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRFC.score(X_test4, y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None,\n",
    "                             max_features='sqrt', min_samples_split=2,\n",
    "                             oob_score=True,n_jobs=4, criterion= 'gini')\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(X_train4, y_train4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clfRFC, open('forest.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b933d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions on the test dataset\n",
    "y_pred4 = clf.predict(X_test4)\n",
    "accuracy_forest = accuracy_score(y_test4, y_pred4) * 100\n",
    "print(clf.score(X_test4, y_test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfe1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions on the trial dataset\n",
    "y_pred4_trial = clf.predict(X_trial4)\n",
    "accuracy_forest_trial = accuracy_score(y_trial4, y_pred4_trial) * 100\n",
    "print(clf.score(X_trial4, y_trial4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test4, y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_forest = recall_score(y_test4, y_pred4, average='weighted') * 100\n",
    "precision_forest = precision_score(y_test4, y_pred4, average='weighted', zero_division=0) * 100\n",
    "f1_forest = f1_score(y_test4, y_pred4, average='weighted') * 100\n",
    "balanced_forest = balanced_accuracy_score(y_test4, y_pred4) * 100\n",
    "\n",
    "print('Accuracy:', accuracy_forest, '%')\n",
    "print('Recall:', recall_forest, '%')\n",
    "print('Precision:', precision_forest, '%')\n",
    "print('F1:', f1_forest, '%')\n",
    "print('Balanced Accuracy:', balanced_forest, '%')\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ecff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Attributes of the model bag\n",
    "clf.base_estimator_ # Base estimator: Base configuration of each model\n",
    "clf.estimators_ # list of individual models created in each iteration\n",
    "clf.estimator_params # extraction of the configurable parameters of each estimator\n",
    "score = clf.score(x,y) # Model fit metric\n",
    "#modelo.oob_score_ # Out-of-the-bag data score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualizar el arbol de decision\n",
    "\n",
    "tree.plot_tree(clf.estimators_[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db074454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "Yprob_train_rf = clf.predict_proba(X_train4)[:,1]\n",
    "Yprob_test_rf = clf.predict_proba(X_test4)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e0558",
   "metadata": {},
   "source": [
    "## Multilayer perceptron for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceac9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = len(list(X_train5.columns))\n",
    "neuron_quant = [n_inputs, n_inputs+2,n_inputs+4,n_inputs+8,n_inputs+16,n_inputs+32,n_inputs+64]\n",
    "quant_hidden = [1,2]\n",
    "learning_rate = [0.01,0.1,0.5,1]\n",
    "batch_size = [1,8,16]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da900e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e320d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recc = []\n",
    "fitness=0\n",
    "model_best =[]\n",
    "for i in neuron_quant:\n",
    "    for j in quant_hidden:\n",
    "        for k in batch_size:\n",
    "                \n",
    "               \n",
    "\n",
    "                # Agregar: learning rate, momentum, nesterov, dropout, modificar capas, neuronas por capa, funcion activacion\n",
    "                # por capa.\n",
    "                n_inputs = len(list(X_train5.columns))\n",
    "                # Neural network structure\n",
    "                model = Sequential()\n",
    "                \n",
    "                model.add(Dense(n_inputs, activation='sigmoid', input_shape=(n_inputs,)))\n",
    "                # model.add(Dense(10, activation='softplus'))\n",
    "                model.add(Dense(i, activation='sigmoid'))\n",
    "                model.add(Dense(4, activation='softmax'))\n",
    "                # Optimizer configuration\n",
    "                # model.compile(loss='binary_crossentropy',\n",
    "                # with no one hot encoding\n",
    "                #model.compile(loss='sparse_categorical_crossentropy',\n",
    "                #              optimizer='Adam',\n",
    "                #              metrics=['accuracy'])\n",
    "                # with one hot encoding\n",
    "                model.compile(loss='categorical_crossentropy',\n",
    "                              optimizer='Adam',\n",
    "                              metrics=['accuracy'])\n",
    "                model_history = model.fit(X_train5, Y_train_dum, epochs=50, batch_size=k, verbose=1,\n",
    "                                         validation_data=(X_test5,Y_test_dum))\n",
    "                score = model.evaluate(X_test5, Y_test_dum,verbose=1)\n",
    "                Y_prob = model.predict(X_test5)\n",
    "                R2_score_val = r2_score(Y_test_dum, Y_prob)\n",
    "                metric = tfa.metrics.F1Score(num_classes=4, threshold=0.5)\n",
    "                metric.update_state(Y_test_dum, Y_prob)\n",
    "                result = metric.result()\n",
    "                result_mean= np.mean(result)\n",
    "\n",
    "                result.numpy()\n",
    "                if result_mean > fitness:\n",
    "                    model_best = model\n",
    "                fitness = result_mean\n",
    "                \n",
    "                #model.evalu model.evaluate(x_test, y_test, batch_size=128) \n",
    "                recc.append(model_history)\n",
    "model.save_weights(route+'weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.save_weights(route+'weights1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad89df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb7e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_best, open('mlp1.1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c875cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% View the training performance\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.subplot(121)\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.xlabel('Epochs'), plt.ylabel('Loss function')\n",
    "plt.subplot(122)\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.xlabel('Epochs'), plt.ylabel('Accuracy function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d727bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Neural network weights\n",
    "model_best.layers[0].get_weights()\n",
    "# model.get_config() #model configuration\n",
    "# %% View the model\n",
    "plot_model(model_best)\n",
    "# plot_model(model, to_file='../figures/P9_fig/model.png', show_shapes=True)\n",
    "# %% Use the model\n",
    "# Latest version\n",
    "Y_prob = model.predict(X_test5)\n",
    "Y_pred = np.argmax(Y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fcbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#see the inputs and outputs\n",
    "plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_best.evaluate(X_test4, Y_test_dum, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e1442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% More metrics\n",
    "\n",
    "Yhat_train = np.argmax(model.predict(X_train5), axis=1)\n",
    "Yhat_test = np.argmax(model.predict(X_test5), axis=1)\n",
    "accu_train = accuracy_score(y_train5, Yhat_train)\n",
    "prec_train = precision_score(y_train5, Yhat_train, average='weighted',zero_division = 1)\n",
    "reca_train = recall_score(y_train5, Yhat_train, average='weighted',zero_division = 1)\n",
    "accu_test = accuracy_score(y_test5, Yhat_test)\n",
    "prec_test = precision_score(y_test5, Yhat_test, average='weighted',zero_division = 0)\n",
    "reca_test = recall_score(y_test5, Yhat_test, average='weighted',zero_division = 0)\n",
    "print(' \\t\\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f' % (accu_train,\n",
    "                                                                                                            prec_train,\n",
    "                                                                                                            reca_train,\n",
    "                                                                                                            accu_test,\n",
    "                                                                                                            prec_test,\n",
    "                                                                                                            reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9854a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Accuracy': [accuracy_martingala, accuracy_logistic, accuracy_naive, accuracy_forest],\n",
    "           'Recall': [recall_martingala, recall_logistic, recall_naive, recall_forest],\n",
    "           'Precision': [precision_martingala, precision_logistic, precision_naive, precision_forest],\n",
    "           'F1': [f1_martingala, f1_logistic, f1_naive, f1_forest],\n",
    "           'Balanced Accuracy': [balanced_martingala, balanced_logistic, balanced_naive, balanced_forest]\n",
    "           }\n",
    "\n",
    "table = pd.DataFrame(results, index=['Martingale', 'Logistic Regression', 'Naive Bayes', 'Random Forest'])\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
